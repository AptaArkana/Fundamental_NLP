# Text Tokenization
<p align='justify'>Tokenisasi adalah proses membagi teks menjadi unit-unit yang lebih kecil yang disebut token. Token dapat berupa kata, kalimat, atau unit lain yang relevan tergantung pada jenis tokenisasi yang diterapkan. Berikut adalah beberapa jenis tokenizer yang sering digunakan dalam pemrosesan teks.</p>

### Note
<p align='justify'>untuk penggunaan library nlp_id akan membuat error NLTK</p>

## 1. Word Tokenizer
<p align='justify'>Word Tokenizer digunakan untuk membagi teks menjadi kata-kata. Tokenisasi ini sering digunakan dalam analisis teks dasar dan pemrosesan bahasa alami (NLP).</p>

## 2. Sentence Tokenizer
<p align='justify'>Sentence Tokenizer digunakan untuk memisahkan teks menjadi kalimat-kalimat. Ini berguna untuk analisis teks di mana struktur kalimat penting.</p>

## 3. Tweet Tokenizer
<p align='justify'>Tweet Tokenizer dirancang khusus untuk memproses teks dari platform media sosial seperti Twitter. Tokenizer ini mempertimbangkan elemen-elemen khusus seperti tagar (#), mention (@), emotikon, dan lainnya.</p>

## N-gram Tokenizer
<p align='justify'>N-gram Tokenizer memecah teks menjadi kelompok kata yang terdiri dari n kata berturut-turut. Ini berguna untuk analisis teks lanjutan, seperti model bahasa dan deteksi urutan kata.</p>

## Kesimpulan
<p align='justify'>Tokenisasi adalah langkah awal yang penting dalam pemrosesan teks dan analisis NLP. Berbagai jenis tokenizer dapat digunakan tergantung pada kebutuhan spesifik, seperti Word Tokenizer untuk membagi teks menjadi kata-kata, Sentence Tokenizer untuk kalimat, Tweet Tokenizer untuk teks media sosial, dan N-gram Tokenizer untuk analisis urutan kata.</p>